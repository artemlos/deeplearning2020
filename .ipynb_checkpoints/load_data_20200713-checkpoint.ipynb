{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers, optimizers\n",
    "from keras.layers import Input, Conv1D, Dense, Flatten, Activation, UpSampling1D, MaxPooling1D, ZeroPadding1D, TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.core import Reshape\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "We use the ECG dataset available [here](https://www.kaggle.com/shayanfazeli/heartbeat/data?select=mitbih_train.csv). There is [an article](https://arxiv.org/pdf/1805.00794.pdf) that uses the dataset, which we can use as a reference. More details about the dataset can be found [here](https://physionet.org/content/apnea-ecg/1.0.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train only on normal cases. --> determine average error.\n",
    "2. Use the error as the threshold for decisions\n",
    "3. Check if the error differs significantly for other classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87554, 188)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/mitbih_train.csv', low_memory=False, header=None)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21892, 188)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/mitbih_test.csv', low_memory=False, header=None)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4046, 188)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = pd.read_csv('data/ptbdb_normal.csv',low_memory=False, header=None)\n",
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10506, 188)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal = pd.read_csv('data/ptbdb_abnormal.csv', low_memory=False, header=None)\n",
    "abnormal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.where(train[187]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.to_numpy()[:,0:186]\n",
    "y_train = train.to_numpy()[:,-1]#.reshape(-1,1)\n",
    "\n",
    "#X_normal = train[train[187]==0]\n",
    "\n",
    "X_train=X_train.reshape(-1,186,1)\n",
    "X_train_normal = X_train[y_train == 0]\n",
    "X_train_normal = X_train_normal[0:5000]\n",
    "X_train_anomaly = X_train[y_train== 1]\n",
    "X_train_anomaly2 = X_train[y_train== 2]\n",
    "X_train_anomaly3 = X_train[y_train== 3]\n",
    "X_train_anomaly4 = X_train[y_train== 4]\n",
    "\n",
    "\n",
    "# TEST data\n",
    "X_test = test.to_numpy()[:,0:186].reshape(-1,186,1)\n",
    "y_test = test.to_numpy()[:,-1]#.reshape(-1,1)\n",
    "\n",
    "X_test_normal = X_test[y_test == 0]\n",
    "X_test_anomaly = X_test[y_test == 1]\n",
    "X_test_anomaly2 = X_test[y_test == 2]\n",
    "X_test_anomaly3 = X_test[y_test == 3]\n",
    "X_test_anomaly4 = X_test[y_test == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72471"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2223"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(train[187]==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normal = train[train[187]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87554, 186, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 186, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_AE(input_shape):\n",
    "        \n",
    "    inputs = Input(shape=input_shape)\n",
    "    encoded = LSTM(32, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = LSTM(16, activation='tanh', return_sequences=False)(encoded)\n",
    "        \n",
    "    decoded = RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = TimeDistributed(Dense(input_shape[1]))(decoded)\n",
    "        \n",
    "    sequence_autoencoder = Model(inputs, decoded)\n",
    "    \n",
    "    return sequence_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_AE_Deep(input_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input shape = (data_dim, number_of_features)\n",
    "    \n",
    "    Returns both the autoencoder and just the encoder.\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    encoded = LSTM(32, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = LSTM(16, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = LSTM(8, activation='tanh', return_sequences=False)(encoded)\n",
    "    #encoded = LSTM(4, activation='relu', return_sequences=False)(encoded)\n",
    "    \n",
    "    decoded = RepeatVector(input_shape[0])(encoded)\n",
    "    #decoded = LSTM(4, activation='relu', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(8, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = TimeDistributed(Dense(input_shape[1]))(decoded)\n",
    "    \n",
    "    sequence_autoencoder = Model(inputs, decoded)\n",
    "    encoder = Model(inputs, encoded)\n",
    "    \n",
    "    return (sequence_autoencoder, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_AE_Deep_v2(input_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input shape = (data_dim, number_of_features)\n",
    "    \n",
    "    Returns both the autoencoder and just the encoder.\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    encoded = LSTM(64, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = LSTM(32, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = LSTM(16, activation='tanh', return_sequences=False)(encoded)\n",
    "    #encoded = LSTM(4, activation='relu', return_sequences=False)(encoded)\n",
    "    \n",
    "    decoded = RepeatVector(input_shape[0])(encoded)\n",
    "    #decoded = LSTM(4, activation='relu', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = TimeDistributed(Dense(input_shape[1]))(decoded)\n",
    "    \n",
    "    sequence_autoencoder = Model(inputs, decoded)\n",
    "    encoder = Model(inputs, encoded)\n",
    "    \n",
    "    return (sequence_autoencoder, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_AE_Deep_v3(input_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input shape = (data_dim, number_of_features)\n",
    "    \n",
    "    Returns both the autoencoder and just the encoder.\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    encoded = LSTM(128, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = LSTM(64, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = LSTM(32, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = LSTM(16, activation='tanh', return_sequences=False)(encoded)\n",
    "    #encoded = LSTM(4, activation='relu', return_sequences=False)(encoded)\n",
    "    \n",
    "    decoded = RepeatVector(input_shape[0])(encoded)\n",
    "    #decoded = LSTM(4, activation='relu', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(128, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = TimeDistributed(Dense(input_shape[1]))(decoded)\n",
    "    \n",
    "    sequence_autoencoder = Model(inputs, decoded)\n",
    "    encoder = Model(inputs, encoded)\n",
    "    \n",
    "    return (sequence_autoencoder, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TCN_AE(input_shape = (100,8)):  \n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    filter_c = input_shape[0]#+input_shape[1] -1\n",
    "    \n",
    "    #encoder\n",
    "    \n",
    "    x = Conv1D(filters=int(filter_c), kernel_size=2, dilation_rate=1,\n",
    "                   padding='causal', strides=1, input_shape=input_shape,\n",
    "                   kernel_regularizer = regularizers.l2(0.01), activation='relu')(input_layer)\n",
    "    x = MaxPooling1D(pool_size = 2, strides=2)(x)\n",
    "    x = Conv1D(filters=int(filter_c/2), kernel_size=2, dilation_rate=1,\n",
    "                   padding='causal', strides=1, \n",
    "                   kernel_regularizer = regularizers.l2(0.01), activation='relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 2, strides=2)(x)\n",
    "    x = Conv1D(filters=int(filter_c/4), kernel_size=2, dilation_rate=1,\n",
    "                   padding='causal', strides=1, \n",
    "                   kernel_regularizer = regularizers.l2(0.01), activation='relu')(x)\n",
    "    x = MaxPooling1D(pool_size = 2, strides=2)(x)\n",
    "    x = Conv1D(filters=int(filter_c/8), kernel_size=2, dilation_rate=1,\n",
    "                   padding='causal', strides=1, \n",
    "                   kernel_regularizer = regularizers.l2(0.01), activation='relu')(x)\n",
    "    x = Dense(int(filter_c/16), activation='relu')(x)\n",
    "    encoder = Model(input_layer, x)\n",
    "    \n",
    "    #decoder\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    x = Conv1D(filters=int(filter_c/8), kernel_size=2, dilation_rate=1,\n",
    "                   padding='causal', strides=1, \n",
    "                   kernel_regularizer = regularizers.l2(0.01), activation='relu')(x)\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    x = Conv1D(filters=int(filter_c/4), kernel_size=2, dilation_rate=1,\n",
    "                   padding='causal', strides=1, \n",
    "                   kernel_regularizer = regularizers.l2(0.01), activation='relu')(x)\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    x = Conv1D(filters=int(filter_c/2), kernel_size=2, dilation_rate=1,\n",
    "                   padding='causal', strides=1, \n",
    "                   kernel_regularizer = regularizers.l2(0.01), activation='relu')(x)\n",
    "    x = ZeroPadding1D(padding=(0,4))(x)\n",
    "    x = Conv1D(filters=int(filter_c), kernel_size=2, dilation_rate=1,\n",
    "                   padding='causal', strides=1, input_shape=input_shape,\n",
    "                   kernel_regularizer = regularizers.l2(0.01), activation='relu')(x)\n",
    "    #flat = Flatten()(conv_6)\n",
    "    output_layer = TimeDistributed(Dense(input_shape[1]))(x)\n",
    "    \n",
    "    TCN = Model(inputs = input_layer, outputs = output_layer)\n",
    "            \n",
    "    return (TCN, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 186, 1)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 186, 32)           4352      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 186, 16)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 186, 16)           2112      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 186, 32)           6272      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 186, 1)            33        \n",
      "=================================================================\n",
      "Total params: 15,905\n",
      "Trainable params: 15,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_AE((186,1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mae', metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 186, 1)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 186, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 186, 32)           12416     \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "repeat_vector_5 (RepeatVecto (None, 186, 16)           0         \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 186, 16)           2112      \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 186, 32)           6272      \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 186, 64)           24832     \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 186, 1)            65        \n",
      "=================================================================\n",
      "Total params: 65,729\n",
      "Trainable params: 65,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_AE_Deep_v2((186,1))[0]\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mae', metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 186, 1)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 186, 64)           16896     \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 186, 32)           12416     \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "repeat_vector_6 (RepeatVecto (None, 186, 16)           0         \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 186, 16)           2112      \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 186, 32)           6272      \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, 186, 64)           24832     \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 186, 128)          98816     \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 186, 1)            129       \n",
      "=================================================================\n",
      "Total params: 164,609\n",
      "Trainable params: 164,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_AE_Deep_v3((186,1))[0]\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mae', metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 186, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 186, 186)          558       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 93, 186)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 93, 46)            17158     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 46, 46)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 46, 46)            4278      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 23, 46)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 23, 23)            2139      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 23, 11)            264       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_21 (UpSampling (None, 46, 11)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 46, 23)            529       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_22 (UpSampling (None, 92, 23)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 92, 46)            2162      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_23 (UpSampling (None, 184, 46)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 184, 93)           8649      \n",
      "_________________________________________________________________\n",
      "zero_padding1d_7 (ZeroPaddin (None, 188, 93)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 188, 186)          34782     \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 188, 1)            187       \n",
      "=================================================================\n",
      "Total params: 70,706\n",
      "Trainable params: 70,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: output shape does not seem ok.\n",
    "#model = TCN_AE((186,1))[0]\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "149/149 [==============================] - 104s 695ms/step - loss: 0.1363 - val_loss: 0.1022\n",
      "Epoch 2/5\n",
      " 28/149 [====>.........................] - ETA: 1:01 - loss: 0.1073"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_normal, X_train_normal, epochs=5, verbose=1, shuffle=True, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model on train\n",
    "We will now compute the the loss for each class on the train set. This will guide us in setting a decision boundary, that we can later use on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 186, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train_normal).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-d3805b899cfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_normal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_mae_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX_train_normal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artem los\\.conda\\envs\\tf_prod\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mc:\\users\\artem los\\.conda\\envs\\tf_prod\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1266\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m             \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artem los\\.conda\\envs\\tf_prod\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artem los\\.conda\\envs\\tf_prod\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    616\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\users\\artem los\\.conda\\envs\\tf_prod\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artem los\\.conda\\envs\\tf_prod\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artem los\\.conda\\envs\\tf_prod\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artem los\\.conda\\envs\\tf_prod\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\artem los\\.conda\\envs\\tf_prod\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train_pred = model.predict(X_train_normal)\n",
    "train_mae_loss = np.mean(np.abs(x_train_pred - X_train_normal), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_mae_loss, bins=10)\n",
    "plt.xlabel(\"Train MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(train_mae_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(X_train_normal,X_train_normal, verbose=3))\n",
    "print(model.evaluate(X_train_anomaly2,X_train_anomaly2, verbose=3))\n",
    "print(model.evaluate(X_train_anomaly3,X_train_anomaly3, verbose=3))\n",
    "print(model.evaluate(X_train_anomaly4,X_train_anomaly4, verbose=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and test set\n",
    "It's clear that our model (trained on fewer samples than we have) detects most of the nomalies (except class 3). Now, let's do the same on the test set. We can set the decision boundary to `0.16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07309737056493759\n",
      "0.07742656022310257\n",
      "0.09911613911390305\n",
      "0.07295534014701843\n",
      "0.09004269540309906\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test_normal,X_test_normal, verbose=3))\n",
    "print(model.evaluate(X_test_anomaly,X_test_anomaly, verbose=3))\n",
    "print(model.evaluate(X_test_anomaly2,X_test_anomaly2, verbose=3))\n",
    "print(model.evaluate(X_test_anomaly3,X_test_anomaly3, verbose=3))\n",
    "print(model.evaluate(X_test_anomaly4,X_test_anomaly4, verbose=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from errormetrics import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normal_pred = model.predict(X_test_normal)\n",
    "normal_mae_loss = np.mean(np.abs(x_normal_pred - X_test_normal), axis=1)\n",
    "\n",
    "x_anomaly_pred = model.predict(X_test_anomaly)\n",
    "anomaly_mae_loss = np.mean(np.abs(x_anomaly_pred - X_test_anomaly), axis=1)\n",
    "\n",
    "x_anomaly2_pred = model.predict(X_test_anomaly2)\n",
    "anomaly2_mae_loss = np.mean(np.abs(x_anomaly2_pred - X_test_anomaly2), axis=1)\n",
    "\n",
    "x_anomaly3_pred = model.predict(X_test_anomaly3)\n",
    "anomaly3_mae_loss = np.mean(np.abs(x_anomaly3_pred - X_test_anomaly3), axis=1)\n",
    "\n",
    "x_anomaly4_pred = model.predict(X_test_anomaly4)\n",
    "anomaly4_mae_loss = np.mean(np.abs(x_anomaly4_pred - X_test_anomaly4), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_threshold = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set with normal samples\n",
    "\n",
    "# \"positive\" means it's normal. \"negative\" means there is an anomaly.\n",
    "\n",
    "def compute_metrics(error_threshold):\n",
    "    FN = len(normal_mae_loss[normal_mae_loss>=error_threshold])\n",
    "    TP = len(normal_mae_loss[normal_mae_loss<error_threshold])\n",
    "\n",
    "    FP = len(anomaly_mae_loss[anomaly_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly2_mae_loss[anomaly2_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly3_mae_loss[anomaly3_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly4_mae_loss[anomaly4_mae_loss<error_threshold])\n",
    "\n",
    "    TN = len(anomaly_mae_loss[anomaly_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly2_mae_loss[anomaly2_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly3_mae_loss[anomaly3_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly4_mae_loss[anomaly4_mae_loss>=error_threshold])\n",
    "\n",
    "\n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    F1_score = 2* (precision * recall)/(precision + recall)\n",
    "    accurracy = (TP + TN) / (TP+TN+FP+FN)\n",
    "\n",
    "    print(precision, \"precision\")\n",
    "    print(recall, \"recall\")\n",
    "    print(F1_score, \"F1 score\")\n",
    "    print(accurracy, \"accurracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827720148060138 precision\n",
      "0.9997240313500386 recall\n",
      "0.9056273593160171 F1 score\n",
      "0.8275625799378769 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8276082587246483 precision\n",
      "1.0 recall\n",
      "0.9056735816045989 F1 score\n",
      "0.8276082587246483 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.32506953328046745)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_pred = model.predict(X_test_anomaly)\n",
    "test_mae_loss = np.mean(np.abs(x_test_pred - X_test_anomaly), axis=1)\n",
    "plt.hist(test_mae_loss, bins=10)\n",
    "plt.xlabel(\"Test MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "#predicted_class1 = []\n",
    "\n",
    "\n",
    "predicted_bad = test_mae_loss[test_mae_loss>0.15]\n",
    "predicted_ok = test_mae_loss[test_mae_loss<0.15]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(len(predicted_ok))\n",
    "print(len(predicted_bad))\n",
    "\n",
    "for sample in X_test_anomaly:\n",
    "    if model.evaluate(sample, sample, verbose=3) > 0.08:\n",
    "        predicted_class1.append(1)\n",
    "    else:\n",
    "        predicted_class1.append(0)\n",
    "\"\"\"\n",
    "\n",
    "print(len(predicted_ok))\n",
    "print(len(predicted_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class2 = []\n",
    "\n",
    "for sample in X_test_anomaly2:\n",
    "    if model.evaluate(sample, sample, verbose=3) > 0.08:\n",
    "        predicted_class2.append(1)\n",
    "    else:\n",
    "        predicted_class2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_pred = model.predict(X_test_anomaly3)\n",
    "test_mae_loss = np.mean(np.abs(x_test_pred - X_test_anomaly3), axis=1)\n",
    "plt.hist(test_mae_loss, bins=10)\n",
    "plt.xlabel(\"Test MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
