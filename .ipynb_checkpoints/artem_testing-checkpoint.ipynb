{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "\n",
    "use_gpu = False\n",
    "model_prefix = \"_deep_v2\"\n",
    "epoches = 100\n",
    "\n",
    "# use gpu\n",
    "if use_gpu:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "    # print(tf.config.list_physical_devices('GPU'))\n",
    "    print(\"GPU built with CUDA: %s\" % tf.test.is_built_with_cuda())\n",
    "    print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
    "\n",
    "# Dataset\n",
    "# We use the ECG dataset available [here](https://www.kaggle.com/shayanfazeli/heartbeat/data?select=mitbih_train.csv). There is [an article](https://arxiv.org/pdf/1805.00794.pdf) that uses the dataset, which we can use as a reference. More details about the dataset can be found [here](https://physionet.org/content/apnea-ecg/1.0.0/)\n",
    "# 1. Train only on normal cases. --> determine average error.\n",
    "# 2. Use the error as the threshold for decisions\n",
    "# 3. Check if the error differs significantly for other classes.\n",
    "\n",
    "# load data\n",
    "train = pd.read_csv('data/mitbih_train.csv', low_memory=False, header=None)\n",
    "test = pd.read_csv('data/mitbih_test.csv', low_memory=False, header=None)\n",
    "\n",
    "## Split into X and y\n",
    "\n",
    "X_train = train.to_numpy()[:, 0:186]\n",
    "y_train = train.to_numpy()[:, -1]\n",
    "\n",
    "X_train = X_train.reshape(-1, 186, 1)\n",
    "X_train_normal = X_train[y_train == 0]\n",
    "X_train_anomaly = X_train[y_train == 1]\n",
    "X_train_anomaly2 = X_train[y_train == 2]\n",
    "X_train_anomaly3 = X_train[y_train == 3]\n",
    "X_train_anomaly4 = X_train[y_train == 4]\n",
    "\n",
    "# TEST data\n",
    "X_test = test.to_numpy()[:, 0:186].reshape(-1, 186, 1)\n",
    "y_test = test.to_numpy()[:, -1]\n",
    "\n",
    "X_test_normal = X_test[y_test == 0]\n",
    "X_test_anomaly = X_test[y_test == 1]\n",
    "X_test_anomaly2 = X_test[y_test == 2]\n",
    "X_test_anomaly3 = X_test[y_test == 3]\n",
    "X_test_anomaly4 = X_test[y_test == 4]\n",
    "\n",
    "\n",
    "def LSTM_AE(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    encoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=False)(encoded)\n",
    "\n",
    "    decoded = tf.keras.layers.RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(input_shape[1]))(decoded)\n",
    "\n",
    "    sequence_autoencoder = tf.keras.Model(inputs, decoded)\n",
    "\n",
    "    return sequence_autoencoder\n",
    "\n",
    "\n",
    "def LSTM_AE_Deep(input_shape):\n",
    "    \"\"\"\n",
    "    Input shape = (data_dim, number_of_features)\n",
    "\n",
    "    Returns both the autoencoder and just the encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    encoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = tf.keras.layers.LSTM(8, activation='tanh', return_sequences=False)(encoded)\n",
    "\n",
    "    decoded = tf.keras.layers.RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = tf.keras.layers.LSTM(8, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(input_shape[1]))(decoded)\n",
    "\n",
    "    sequence_autoencoder = tf.keras.Model(inputs, decoded)\n",
    "\n",
    "    return sequence_autoencoder\n",
    "\n",
    "\n",
    "def LSTM_AE_Deep_v2(input_shape):\n",
    "    \"\"\"\n",
    "    Input shape = (data_dim, number_of_features)\n",
    "\n",
    "    Returns both the autoencoder and just the encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    encoded = tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=False)(encoded)\n",
    "\n",
    "    decoded = tf.keras.layers.RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(input_shape[1]))(decoded)\n",
    "\n",
    "    sequence_autoencoder = tf.keras.Model(inputs, decoded)\n",
    "\n",
    "    return sequence_autoencoder\n",
    "\n",
    "\n",
    "def LSTM_AE_Deep_v3(input_shape):\n",
    "    \"\"\"\n",
    "    Input shape = (data_dim, number_of_features)\n",
    "\n",
    "    Returns both the autoencoder and just the encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    encoded = tf.keras.layers.LSTM(128, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=False)(encoded)\n",
    "\n",
    "    decoded = tf.keras.layers.RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(128, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(input_shape[1]))(decoded)\n",
    "\n",
    "    sequence_autoencoder = tf.keras.Model(inputs, decoded)\n",
    "\n",
    "    return sequence_autoencoder\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    checkpoint_dir = \"run\"\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger(\n",
    "        os.path.join(checkpoint_dir, \"log\" + model_prefix + \".csv\"))  # to save epoch results in csv file\n",
    "    model.fit(X_train_normal, X_train_normal, epochs=epoches, verbose=1, shuffle=True,\n",
    "              validation_split=0.05, callbacks=[csv_logger])\n",
    "\n",
    "    # important to change file name for new model configs, so we dont overwrite existing files\n",
    "    model.save_weights(os.path.join(checkpoint_dir, \"final_weights\" + model_prefix + \".h5\"))\n",
    "\n",
    "    ### Apply model on train\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_error_metrics(model):\n",
    "    # We will now compute the the loss for each class on the train set. This will guide us in setting a decision boundary, that we can later use on the test set.\n",
    "    x_train_pred = model.predict(X_train_normal)\n",
    "    train_mae_loss = np.mean(np.abs(x_train_pred - X_train_normal), axis=1)\n",
    "\n",
    "    plt.hist(train_mae_loss, bins=10)\n",
    "    plt.xlabel(\"Train MAE loss\")\n",
    "    plt.ylabel(\"No of samples\")\n",
    "    plt.savefig(\"Train_mae_loss\" + model_prefix + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"max training mae loss: %s\" % np.max(train_mae_loss))\n",
    "\n",
    "    # you should manually choose or use some heurestics to determine a proper error_threshold\n",
    "    error_threshold = model.evaluate(X_train_normal, X_train_normal, verbose=3)\n",
    "    print(\"Chosen error threshold: %s\" % error_threshold)\n",
    "    # print(model.evaluate(X_train_anomaly2,X_train_anomaly2, verbose=3))\n",
    "    # print(model.evaluate(X_train_anomaly3,X_train_anomaly3, verbose=3))\n",
    "    # print(model.evaluate(X_train_anomaly4,X_train_anomaly4, verbose=3))\n",
    "    ### Conclusion and test set\n",
    "    # It's clear that our model (trained on fewer samples than we have) detects most of the nomalies (except class 3). Now, let's do the same on the test set. We can set the decision boundary to `0.16`.\n",
    "\n",
    "    # print(model.evaluate(X_test_normal,X_test_normal, verbose=3))\n",
    "    # print(model.evaluate(X_test_anomaly,X_test_anomaly, verbose=3))\n",
    "    # print(model.evaluate(X_test_anomaly2,X_test_anomaly2, verbose=3))\n",
    "    # print(model.evaluate(X_test_anomaly3,X_test_anomaly3, verbose=3))\n",
    "    # print(model.evaluate(X_test_anomaly4,X_test_anomaly4, verbose=3))\n",
    "\n",
    "    x_normal_pred = model.predict(X_test_normal)\n",
    "    normal_mae_loss = np.mean(np.abs(x_normal_pred - X_test_normal), axis=1)\n",
    "    x_anomaly_pred = model.predict(X_test_anomaly)\n",
    "    anomaly_mae_loss = np.mean(np.abs(x_anomaly_pred - X_test_anomaly), axis=1)\n",
    "    x_anomaly2_pred = model.predict(X_test_anomaly2)\n",
    "    anomaly2_mae_loss = np.mean(np.abs(x_anomaly2_pred - X_test_anomaly2), axis=1)\n",
    "    x_anomaly3_pred = model.predict(X_test_anomaly3)\n",
    "    anomaly3_mae_loss = np.mean(np.abs(x_anomaly3_pred - X_test_anomaly3), axis=1)\n",
    "    x_anomaly4_pred = model.predict(X_test_anomaly4)\n",
    "    anomaly4_mae_loss = np.mean(np.abs(x_anomaly4_pred - X_test_anomaly4), axis=1)\n",
    "\n",
    "    # \"positive\" means it's normal. \"negative\" means there is an anomaly.\n",
    "    def compute_metrics(error_threshold):\n",
    "        FN = len(normal_mae_loss[normal_mae_loss >= error_threshold])\n",
    "        TP = len(normal_mae_loss[normal_mae_loss < error_threshold])\n",
    "\n",
    "        FP = len(anomaly_mae_loss[anomaly_mae_loss < error_threshold]) + \\\n",
    "             len(anomaly2_mae_loss[anomaly2_mae_loss < error_threshold]) + \\\n",
    "             len(anomaly3_mae_loss[anomaly3_mae_loss < error_threshold]) + \\\n",
    "             len(anomaly4_mae_loss[anomaly4_mae_loss < error_threshold])\n",
    "\n",
    "        TN = len(anomaly_mae_loss[anomaly_mae_loss >= error_threshold]) + \\\n",
    "             len(anomaly2_mae_loss[anomaly2_mae_loss >= error_threshold]) + \\\n",
    "             len(anomaly3_mae_loss[anomaly3_mae_loss >= error_threshold]) + \\\n",
    "             len(anomaly4_mae_loss[anomaly4_mae_loss >= error_threshold])\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        F1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        accurracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "        print(precision, \"precision\")\n",
    "        print(recall, \"recall\")\n",
    "        print(F1_score, \"F1 score\")\n",
    "        print(accurracy, \"accurracy\")\n",
    "        print(error_threshold, \"error_threshold\")\n",
    "\n",
    "        content = \"Precision: %s\\nRecall: %s\\nF1_score: %s\\nAccuracy: %s\\nError_threshold: %s\" \\\n",
    "                  % (precision, recall, F1_score, accurracy, error_threshold)\n",
    "        return content\n",
    "\n",
    "    print(\"Compute metrics with {} error threshold\".format(error_threshold))\n",
    "    content = compute_metrics(error_threshold)\n",
    "    write_to_file(os.path.join(\"run\", \"error_metrics_proper_error\" + model_prefix), content)\n",
    "\n",
    "    print()\n",
    "    max_error_threshold = np.max(train_mae_loss)\n",
    "    print(\"Compute metrics with {} error threshold\".format(max_error_threshold))\n",
    "    content = compute_metrics(max_error_threshold)\n",
    "    write_to_file(os.path.join(\"run\", \"error_metrics_max_error\" + model_prefix), content)\n",
    "\n",
    "\n",
    "def plot_loss():\n",
    "    headers = [\"epoches\", \"training_loss\", \"validation_loss\"]\n",
    "    df = pd.read_csv(os.path.join(\"run\", \"log\" + model_prefix + \".csv\"), names=headers)\n",
    "    training_loss = df[\"training_loss\"].to_numpy()[1:].astype(np.float)\n",
    "    validation_loss = df[\"validation_loss\"].to_numpy()[1:].astype(np.float)\n",
    "    plt.plot(training_loss, label=\"Training\")\n",
    "    plt.plot(validation_loss, label=\"Validation\")\n",
    "    plt.xlabel('Epoches')\n",
    "    plt.ylabel('Loss')\n",
    "    # plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"loss\" + model_prefix + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, \"w\", encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = (186, 1)\n",
    "#model = LSTM_AE(input_shape)\n",
    "model = LSTM_AE_Deep(input_shape)\n",
    "#model = LSTM_AE_Deep_v3(input_shape)\n",
    "# model = LSTM_AE_Deep_v3(input_shape)\n",
    "#model.summary()\n",
    "#model.compile(optimizer='adam', loss='mae', metrics=None)\n",
    "\n",
    "load_weights = True\n",
    "model_prefix_to_load = \"_deep\"  # change this to whichever version you want to load\n",
    "\n",
    "if load_weights:\n",
    "    model.load_weights(os.path.join(\"run\", \"final_weights\" + model_prefix_to_load + \".h5\"))\n",
    "else:\n",
    "    model = train(model)\n",
    "\n",
    "#plot_error_metrics(model)\n",
    "#plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding threshold\n",
    "\n",
    "We use the train set to find the threshold that maximises accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normal_pred = model.predict(X_train_normal)\n",
    "normal_mae_loss = np.mean(np.abs(x_normal_pred - X_train_normal), axis=1)\n",
    "\n",
    "x_anomaly_pred = model.predict(X_train_anomaly)\n",
    "anomaly_mae_loss = np.mean(np.abs(x_anomaly_pred - X_train_anomaly), axis=1)\n",
    "\n",
    "x_anomaly2_pred = model.predict(X_train_anomaly2)\n",
    "anomaly2_mae_loss = np.mean(np.abs(x_anomaly2_pred - X_train_anomaly2), axis=1)\n",
    "\n",
    "x_anomaly3_pred = model.predict(X_train_anomaly3)\n",
    "anomaly3_mae_loss = np.mean(np.abs(x_anomaly3_pred - X_train_anomaly3), axis=1)\n",
    "\n",
    "x_anomaly4_pred = model.predict(X_train_anomaly4)\n",
    "anomaly4_mae_loss = np.mean(np.abs(x_anomaly4_pred - X_train_anomaly4), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(error_threshold):\n",
    "    FN = len(normal_mae_loss[normal_mae_loss>=error_threshold])\n",
    "    TP = len(normal_mae_loss[normal_mae_loss<error_threshold])\n",
    "\n",
    "    FP = len(anomaly_mae_loss[anomaly_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly2_mae_loss[anomaly2_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly3_mae_loss[anomaly3_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly4_mae_loss[anomaly4_mae_loss<error_threshold])\n",
    "\n",
    "    TN = len(anomaly_mae_loss[anomaly_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly2_mae_loss[anomaly2_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly3_mae_loss[anomaly3_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly4_mae_loss[anomaly4_mae_loss>=error_threshold])\n",
    "\n",
    "    if TP == 0 and FP == 0 or TP == 0 and FN==0:\n",
    "        return 0\n",
    "\n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    F1_score = 2* (precision * recall)/(precision + recall)\n",
    "    accurracy = (TP + TN) / (TP+TN+FP+FN)\n",
    "\n",
    "    print(precision, \"precision\")\n",
    "    print(recall, \"recall\")\n",
    "    print(F1_score, \"F1 score\")\n",
    "    print(accurracy, \"accurracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(error_threshold, metric='accuracy'):\n",
    "    FN = len(normal_mae_loss[normal_mae_loss>=error_threshold])\n",
    "    TP = len(normal_mae_loss[normal_mae_loss<error_threshold])\n",
    "\n",
    "    FP = len(anomaly_mae_loss[anomaly_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly2_mae_loss[anomaly2_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly3_mae_loss[anomaly3_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly4_mae_loss[anomaly4_mae_loss<error_threshold])\n",
    "\n",
    "    TN = len(anomaly_mae_loss[anomaly_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly2_mae_loss[anomaly2_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly3_mae_loss[anomaly3_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly4_mae_loss[anomaly4_mae_loss>=error_threshold])\n",
    "\n",
    "    if TP == 0 and FP == 0 or TP == 0 and FN==0:\n",
    "        return 0\n",
    "    \n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    F1_score = 2* (precision * recall)/(precision + recall)\n",
    "    accuracy = (TP + TN) / (TP+TN+FP+FN)\n",
    "    \n",
    "    if metric=='accuracy':\n",
    "        return accuracy\n",
    "    elif metric=='f1_score':\n",
    "        return F1_score\n",
    "    elif metric=='precision':\n",
    "        return precision\n",
    "    else:\n",
    "        raise ValueError('Not a valid metric')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "def anneal(sol, metric='accuracy',it=100):\n",
    "    old_cost = cost_function(sol, metric)\n",
    "    T = 1.0\n",
    "    T_min = 0.00001\n",
    "    alpha = 0.9\n",
    "    while T > T_min:\n",
    "        i = 1\n",
    "        while i <= it:\n",
    "            new_sol = neighbor(sol)\n",
    "            new_cost = cost_function(new_sol, metric)\n",
    "            ap = acceptance_probability(old_cost, new_cost, T)\n",
    "            if ap > random.random():\n",
    "                sol = new_sol\n",
    "                old_cost = new_cost\n",
    "            i += 1\n",
    "        T = T*alpha\n",
    "    return sol, old_cost\n",
    "\n",
    "def acceptance_probability(old_cost, new_cost, T):\n",
    "    return math.exp((new_cost-old_cost)/T)\n",
    "\n",
    "def neighbor(sol):\n",
    "    #return sol + random.random()/100-0.005\n",
    "    return random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.675888972042563, 0.905782066345024)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original (final_weights1.h5)\n",
    "anneal(0.15, metric='f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8278178225060258 precision\n",
      "0.9999586041313077 recall\n",
      "0.905782066345024 F1 score\n",
      "0.8278091235123467 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.675888972042563)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.042737895911668766, 0.9517399824312454)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deep_results\n",
    "anneal(0.15, metric='f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9325335346071849 precision\n",
      "0.9717542189289509 recall\n",
      "0.9517399824312454 F1 score\n",
      "0.9184274847522672 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.042737895911668766)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.003970321658651632, 1.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deep_v2_results\n",
    "anneal(0.15, metric='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 precision\n",
      "0.00044155593271791473 recall\n",
      "0.0008827220942581685 F1 score\n",
      "0.17263631587363226 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.003970321658651632)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.025528328131515843, 1.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deep_v3_results\n",
    "anneal(0.15, metric='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 precision\n",
      "2.759724579486967e-05 recall\n",
      "5.5192968415823826e-05 F1 score\n",
      "0.17229367019211 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.025528328131515843)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing phase\n",
    "We use the obtained metric from the training set to evaluate performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normal_pred = model.predict(X_test_normal)\n",
    "normal_mae_loss = np.mean(np.abs(x_normal_pred - X_test_normal), axis=1)\n",
    "\n",
    "x_anomaly_pred = model.predict(X_test_anomaly)\n",
    "anomaly_mae_loss = np.mean(np.abs(x_anomaly_pred - X_test_anomaly), axis=1)\n",
    "\n",
    "x_anomaly2_pred = model.predict(X_test_anomaly2)\n",
    "anomaly2_mae_loss = np.mean(np.abs(x_anomaly2_pred - X_test_anomaly2), axis=1)\n",
    "\n",
    "x_anomaly3_pred = model.predict(X_test_anomaly3)\n",
    "anomaly3_mae_loss = np.mean(np.abs(x_anomaly3_pred - X_test_anomaly3), axis=1)\n",
    "\n",
    "x_anomaly4_pred = model.predict(X_test_anomaly4)\n",
    "anomaly4_mae_loss = np.mean(np.abs(x_anomaly4_pred - X_test_anomaly4), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8277973226115959 precision\n",
      "1.0 recall\n",
      "0.9057867766529183 F1 score\n",
      "0.8278366526585054 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.675888972042563)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931378763866878 precision\n",
      "0.9731206534937631 recall\n",
      "0.9517922694882315 F1 score\n",
      "0.9184176868262379 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.042737895911668766)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 precision\n",
      "0.0008279059498840931 recall\n",
      "0.0016544421772459051 F1 score\n",
      "0.17307692307692307 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.003970321658651632)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(0.025528328131515843)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
