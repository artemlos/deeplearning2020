{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "\n",
    "use_gpu = False\n",
    "model_prefix = \"_deep_v2\"\n",
    "epoches = 100\n",
    "\n",
    "# use gpu\n",
    "if use_gpu:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "    # print(tf.config.list_physical_devices('GPU'))\n",
    "    print(\"GPU built with CUDA: %s\" % tf.test.is_built_with_cuda())\n",
    "    print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
    "\n",
    "# Dataset\n",
    "# We use the ECG dataset available [here](https://www.kaggle.com/shayanfazeli/heartbeat/data?select=mitbih_train.csv). There is [an article](https://arxiv.org/pdf/1805.00794.pdf) that uses the dataset, which we can use as a reference. More details about the dataset can be found [here](https://physionet.org/content/apnea-ecg/1.0.0/)\n",
    "# 1. Train only on normal cases. --> determine average error.\n",
    "# 2. Use the error as the threshold for decisions\n",
    "# 3. Check if the error differs significantly for other classes.\n",
    "\n",
    "# load data\n",
    "train = pd.read_csv('data/mitbih_train.csv', low_memory=False, header=None)\n",
    "test = pd.read_csv('data/mitbih_test.csv', low_memory=False, header=None)\n",
    "\n",
    "## Split into X and y\n",
    "\n",
    "X_train = train.to_numpy()[:, 0:186]\n",
    "y_train = train.to_numpy()[:, -1]\n",
    "\n",
    "X_train = X_train.reshape(-1, 186, 1)\n",
    "X_train_normal = X_train[y_train == 0]\n",
    "X_train_anomaly = X_train[y_train == 1]\n",
    "X_train_anomaly2 = X_train[y_train == 2]\n",
    "X_train_anomaly3 = X_train[y_train == 3]\n",
    "X_train_anomaly4 = X_train[y_train == 4]\n",
    "\n",
    "# TEST data\n",
    "X_test = test.to_numpy()[:, 0:186].reshape(-1, 186, 1)\n",
    "y_test = test.to_numpy()[:, -1]\n",
    "\n",
    "X_test_normal = X_test[y_test == 0]\n",
    "X_test_anomaly = X_test[y_test == 1]\n",
    "X_test_anomaly2 = X_test[y_test == 2]\n",
    "X_test_anomaly3 = X_test[y_test == 3]\n",
    "X_test_anomaly4 = X_test[y_test == 4]\n",
    "\n",
    "\n",
    "def LSTM_AE(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    encoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=False)(encoded)\n",
    "\n",
    "    decoded = tf.keras.layers.RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(input_shape[1]))(decoded)\n",
    "\n",
    "    sequence_autoencoder = tf.keras.Model(inputs, decoded)\n",
    "\n",
    "    return sequence_autoencoder\n",
    "\n",
    "\n",
    "def LSTM_AE_Deep(input_shape):\n",
    "    \"\"\"\n",
    "    Input shape = (data_dim, number_of_features)\n",
    "\n",
    "    Returns both the autoencoder and just the encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    encoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = tf.keras.layers.LSTM(8, activation='tanh', return_sequences=False)(encoded)\n",
    "\n",
    "    decoded = tf.keras.layers.RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = tf.keras.layers.LSTM(8, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(input_shape[1]))(decoded)\n",
    "\n",
    "    sequence_autoencoder = tf.keras.Model(inputs, decoded)\n",
    "\n",
    "    return sequence_autoencoder\n",
    "\n",
    "\n",
    "def LSTM_AE_Deep_v2(input_shape):\n",
    "    \"\"\"\n",
    "    Input shape = (data_dim, number_of_features)\n",
    "\n",
    "    Returns both the autoencoder and just the encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    encoded = tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=False)(encoded)\n",
    "\n",
    "    decoded = tf.keras.layers.RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(input_shape[1]))(decoded)\n",
    "\n",
    "    sequence_autoencoder = tf.keras.Model(inputs, decoded)\n",
    "\n",
    "    return sequence_autoencoder\n",
    "\n",
    "\n",
    "def LSTM_AE_Deep_v3(input_shape):\n",
    "    \"\"\"\n",
    "    Input shape = (data_dim, number_of_features)\n",
    "\n",
    "    Returns both the autoencoder and just the encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    encoded = tf.keras.layers.LSTM(128, activation='tanh', return_sequences=True)(inputs)\n",
    "    encoded = tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(encoded)\n",
    "    encoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=False)(encoded)\n",
    "\n",
    "    decoded = tf.keras.layers.RepeatVector(input_shape[0])(encoded)\n",
    "    decoded = tf.keras.layers.LSTM(16, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(32, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.LSTM(128, activation='tanh', return_sequences=True)(decoded)\n",
    "    decoded = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(input_shape[1]))(decoded)\n",
    "\n",
    "    sequence_autoencoder = tf.keras.Model(inputs, decoded)\n",
    "\n",
    "    return sequence_autoencoder\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    checkpoint_dir = \"run\"\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger(\n",
    "        os.path.join(checkpoint_dir, \"log\" + model_prefix + \".csv\"))  # to save epoch results in csv file\n",
    "    model.fit(X_train_normal, X_train_normal, epochs=epoches, verbose=1, shuffle=True,\n",
    "              validation_split=0.05, callbacks=[csv_logger])\n",
    "\n",
    "    # important to change file name for new model configs, so we dont overwrite existing files\n",
    "    model.save_weights(os.path.join(checkpoint_dir, \"final_weights\" + model_prefix + \".h5\"))\n",
    "\n",
    "    ### Apply model on train\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_error_metrics(model):\n",
    "    # We will now compute the the loss for each class on the train set. This will guide us in setting a decision boundary, that we can later use on the test set.\n",
    "    x_train_pred = model.predict(X_train_normal)\n",
    "    train_mae_loss = np.mean(np.abs(x_train_pred - X_train_normal), axis=1)\n",
    "\n",
    "    plt.hist(train_mae_loss, bins=10)\n",
    "    plt.xlabel(\"Train MAE loss\")\n",
    "    plt.ylabel(\"No of samples\")\n",
    "    plt.savefig(\"Train_mae_loss\" + model_prefix + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"max training mae loss: %s\" % np.max(train_mae_loss))\n",
    "\n",
    "    # you should manually choose or use some heurestics to determine a proper error_threshold\n",
    "    error_threshold = model.evaluate(X_train_normal, X_train_normal, verbose=3)\n",
    "    print(\"Chosen error threshold: %s\" % error_threshold)\n",
    "    # print(model.evaluate(X_train_anomaly2,X_train_anomaly2, verbose=3))\n",
    "    # print(model.evaluate(X_train_anomaly3,X_train_anomaly3, verbose=3))\n",
    "    # print(model.evaluate(X_train_anomaly4,X_train_anomaly4, verbose=3))\n",
    "    ### Conclusion and test set\n",
    "    # It's clear that our model (trained on fewer samples than we have) detects most of the nomalies (except class 3). Now, let's do the same on the test set. We can set the decision boundary to `0.16`.\n",
    "\n",
    "    # print(model.evaluate(X_test_normal,X_test_normal, verbose=3))\n",
    "    # print(model.evaluate(X_test_anomaly,X_test_anomaly, verbose=3))\n",
    "    # print(model.evaluate(X_test_anomaly2,X_test_anomaly2, verbose=3))\n",
    "    # print(model.evaluate(X_test_anomaly3,X_test_anomaly3, verbose=3))\n",
    "    # print(model.evaluate(X_test_anomaly4,X_test_anomaly4, verbose=3))\n",
    "\n",
    "    x_normal_pred = model.predict(X_test_normal)\n",
    "    normal_mae_loss = np.mean(np.abs(x_normal_pred - X_test_normal), axis=1)\n",
    "    x_anomaly_pred = model.predict(X_test_anomaly)\n",
    "    anomaly_mae_loss = np.mean(np.abs(x_anomaly_pred - X_test_anomaly), axis=1)\n",
    "    x_anomaly2_pred = model.predict(X_test_anomaly2)\n",
    "    anomaly2_mae_loss = np.mean(np.abs(x_anomaly2_pred - X_test_anomaly2), axis=1)\n",
    "    x_anomaly3_pred = model.predict(X_test_anomaly3)\n",
    "    anomaly3_mae_loss = np.mean(np.abs(x_anomaly3_pred - X_test_anomaly3), axis=1)\n",
    "    x_anomaly4_pred = model.predict(X_test_anomaly4)\n",
    "    anomaly4_mae_loss = np.mean(np.abs(x_anomaly4_pred - X_test_anomaly4), axis=1)\n",
    "\n",
    "    # \"positive\" means it's normal. \"negative\" means there is an anomaly.\n",
    "    def compute_metrics(error_threshold):\n",
    "        FN = len(normal_mae_loss[normal_mae_loss >= error_threshold])\n",
    "        TP = len(normal_mae_loss[normal_mae_loss < error_threshold])\n",
    "\n",
    "        FP = len(anomaly_mae_loss[anomaly_mae_loss < error_threshold]) + \\\n",
    "             len(anomaly2_mae_loss[anomaly2_mae_loss < error_threshold]) + \\\n",
    "             len(anomaly3_mae_loss[anomaly3_mae_loss < error_threshold]) + \\\n",
    "             len(anomaly4_mae_loss[anomaly4_mae_loss < error_threshold])\n",
    "\n",
    "        TN = len(anomaly_mae_loss[anomaly_mae_loss >= error_threshold]) + \\\n",
    "             len(anomaly2_mae_loss[anomaly2_mae_loss >= error_threshold]) + \\\n",
    "             len(anomaly3_mae_loss[anomaly3_mae_loss >= error_threshold]) + \\\n",
    "             len(anomaly4_mae_loss[anomaly4_mae_loss >= error_threshold])\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        F1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        accurracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "        print(precision, \"precision\")\n",
    "        print(recall, \"recall\")\n",
    "        print(F1_score, \"F1 score\")\n",
    "        print(accurracy, \"accurracy\")\n",
    "        print(error_threshold, \"error_threshold\")\n",
    "\n",
    "        content = \"Precision: %s\\nRecall: %s\\nF1_score: %s\\nAccuracy: %s\\nError_threshold: %s\" \\\n",
    "                  % (precision, recall, F1_score, accurracy, error_threshold)\n",
    "        return content\n",
    "\n",
    "    print(\"Compute metrics with {} error threshold\".format(error_threshold))\n",
    "    content = compute_metrics(error_threshold)\n",
    "    write_to_file(os.path.join(\"run\", \"error_metrics_proper_error\" + model_prefix), content)\n",
    "\n",
    "    print()\n",
    "    max_error_threshold = np.max(train_mae_loss)\n",
    "    print(\"Compute metrics with {} error threshold\".format(max_error_threshold))\n",
    "    content = compute_metrics(max_error_threshold)\n",
    "    write_to_file(os.path.join(\"run\", \"error_metrics_max_error\" + model_prefix), content)\n",
    "\n",
    "\n",
    "def plot_loss():\n",
    "    headers = [\"epoches\", \"training_loss\", \"validation_loss\"]\n",
    "    df = pd.read_csv(os.path.join(\"run\", \"log\" + model_prefix + \".csv\"), names=headers)\n",
    "    training_loss = df[\"training_loss\"].to_numpy()[1:].astype(np.float)\n",
    "    validation_loss = df[\"validation_loss\"].to_numpy()[1:].astype(np.float)\n",
    "    plt.plot(training_loss, label=\"Training\")\n",
    "    plt.plot(validation_loss, label=\"Validation\")\n",
    "    plt.xlabel('Epoches')\n",
    "    plt.ylabel('Loss')\n",
    "    # plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"loss\" + model_prefix + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, \"w\", encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (186, 1)\n",
    "#model = LSTM_AE(input_shape)\n",
    "model = LSTM_AE_Deep(input_shape)\n",
    "#model = LSTM_AE_Deep_v3(input_shape)\n",
    "# model = LSTM_AE_Deep_v3(input_shape)\n",
    "#model.summary()\n",
    "#model.compile(optimizer='adam', loss='mae', metrics=None)\n",
    "\n",
    "load_weights = True\n",
    "model_prefix_to_load = \"_deep\"  # change this to whichever version you want to load\n",
    "\n",
    "if load_weights:\n",
    "    model.load_weights(os.path.join(\"run\", \"final_weights\" + model_prefix_to_load + \".h5\"))\n",
    "else:\n",
    "    model = train(model)\n",
    "\n",
    "#plot_error_metrics(model)\n",
    "#plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding threshold\n",
    "\n",
    "We use the train set to find the threshold that maximises accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normal_pred = model.predict(X_train_normal)\n",
    "normal_mae_loss = np.mean(np.abs(x_normal_pred - X_train_normal), axis=1)\n",
    "\n",
    "x_anomaly_pred = model.predict(X_train_anomaly)\n",
    "anomaly_mae_loss = np.mean(np.abs(x_anomaly_pred - X_train_anomaly), axis=1)\n",
    "\n",
    "x_anomaly2_pred = model.predict(X_train_anomaly2)\n",
    "anomaly2_mae_loss = np.mean(np.abs(x_anomaly2_pred - X_train_anomaly2), axis=1)\n",
    "\n",
    "x_anomaly3_pred = model.predict(X_train_anomaly3)\n",
    "anomaly3_mae_loss = np.mean(np.abs(x_anomaly3_pred - X_train_anomaly3), axis=1)\n",
    "\n",
    "x_anomaly4_pred = model.predict(X_train_anomaly4)\n",
    "anomaly4_mae_loss = np.mean(np.abs(x_anomaly4_pred - X_train_anomaly4), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(error_threshold):\n",
    "    FN = len(normal_mae_loss[normal_mae_loss>=error_threshold])\n",
    "    TP = len(normal_mae_loss[normal_mae_loss<error_threshold])\n",
    "\n",
    "    FP = len(anomaly_mae_loss[anomaly_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly2_mae_loss[anomaly2_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly3_mae_loss[anomaly3_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly4_mae_loss[anomaly4_mae_loss<error_threshold])\n",
    "\n",
    "    TN = len(anomaly_mae_loss[anomaly_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly2_mae_loss[anomaly2_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly3_mae_loss[anomaly3_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly4_mae_loss[anomaly4_mae_loss>=error_threshold])\n",
    "\n",
    "\n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    F1_score = 2* (precision * recall)/(precision + recall)\n",
    "    accurracy = (TP + TN) / (TP+TN+FP+FN)\n",
    "\n",
    "    print(precision, \"precision\")\n",
    "    print(recall, \"recall\")\n",
    "    print(F1_score, \"F1 score\")\n",
    "    print(accurracy, \"accurracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(error_threshold, metric='accuracy'):\n",
    "    FN = len(normal_mae_loss[normal_mae_loss>=error_threshold])\n",
    "    TP = len(normal_mae_loss[normal_mae_loss<error_threshold])\n",
    "\n",
    "    FP = len(anomaly_mae_loss[anomaly_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly2_mae_loss[anomaly2_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly3_mae_loss[anomaly3_mae_loss<error_threshold]) +\\\n",
    "    len(anomaly4_mae_loss[anomaly4_mae_loss<error_threshold])\n",
    "\n",
    "    TN = len(anomaly_mae_loss[anomaly_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly2_mae_loss[anomaly2_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly3_mae_loss[anomaly3_mae_loss>=error_threshold]) +\\\n",
    "    len(anomaly4_mae_loss[anomaly4_mae_loss>=error_threshold])\n",
    "\n",
    "    if TP == 0 and FP == 0 or TP == 0 and FN==0:\n",
    "        return 0\n",
    "    \n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    F1_score = 2* (precision * recall)/(precision + recall)\n",
    "    accuracy = (TP + TN) / (TP+TN+FP+FN)\n",
    "    \n",
    "    if metric=='accuracy':\n",
    "        return accuracy\n",
    "    elif metric=='f1_score':\n",
    "        return F1_score\n",
    "    else:\n",
    "        raise ValueError('Not a valid metric')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "def anneal(sol, metric='accuracy',it=100):\n",
    "    old_cost = cost_function(sol, metric)\n",
    "    T = 1.0\n",
    "    T_min = 0.00001\n",
    "    alpha = 0.9\n",
    "    while T > T_min:\n",
    "        i = 1\n",
    "        while i <= it:\n",
    "            new_sol = neighbor(sol)\n",
    "            new_cost = cost_function(new_sol, metric)\n",
    "            ap = acceptance_probability(old_cost, new_cost, T)\n",
    "            if ap > random.random():\n",
    "                sol = new_sol\n",
    "                old_cost = new_cost\n",
    "            i += 1\n",
    "        T = T*alpha\n",
    "    return sol, old_cost\n",
    "\n",
    "def acceptance_probability(old_cost, new_cost, T):\n",
    "    return math.exp((new_cost-old_cost)/T)\n",
    "\n",
    "def neighbor(sol):\n",
    "    #return sol + random.random()/100-0.005\n",
    "    return random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04138217998642313, 0.9237270712931448)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original (final_weights1.h5)\n",
    "anneal(0.15, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9396223389327667 precision\n",
      "0.9701949745415408 recall\n",
      "0.9546639511201629 F1 score\n",
      "0.9237270712931448 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.04138217998642313)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.041669843767489834, 0.918507435411289)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deep_results\n",
    "anneal(0.15, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9348659513857459 precision\n",
      "0.9690634874639511 recall\n",
      "0.951657598937619 F1 score\n",
      "0.918507435411289 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.041669843767489834)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.031635346435946565, 0.9138474541425863)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deep_v2_results\n",
    "anneal(0.15, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9442863008074449 precision\n",
      "0.9520911813001063 recall\n",
      "0.9481726798634063 F1 score\n",
      "0.9138474541425863 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.031635346435946565)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5648981081219837, 0.8279690248303904)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deep_v3_results\n",
    "anneal(0.15, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8280026967421983 precision\n",
      "0.9998620137710257 recall\n",
      "0.9058530853085308 F1 score\n",
      "0.8279690248303904 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.5648981081219837)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing phase\n",
    "We use the obtained metric from the training set to evaluate performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normal_pred = model.predict(X_test_normal)\n",
    "normal_mae_loss = np.mean(np.abs(x_normal_pred - X_test_normal), axis=1)\n",
    "\n",
    "x_anomaly_pred = model.predict(X_test_anomaly)\n",
    "anomaly_mae_loss = np.mean(np.abs(x_anomaly_pred - X_test_anomaly), axis=1)\n",
    "\n",
    "x_anomaly2_pred = model.predict(X_test_anomaly2)\n",
    "anomaly2_mae_loss = np.mean(np.abs(x_anomaly2_pred - X_test_anomaly2), axis=1)\n",
    "\n",
    "x_anomaly3_pred = model.predict(X_test_anomaly3)\n",
    "anomaly3_mae_loss = np.mean(np.abs(x_anomaly3_pred - X_test_anomaly3), axis=1)\n",
    "\n",
    "x_anomaly4_pred = model.predict(X_test_anomaly4)\n",
    "anomaly4_mae_loss = np.mean(np.abs(x_anomaly4_pred - X_test_anomaly4), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9396735651802859 precision\n",
      "0.9723479412738713 recall\n",
      "0.9557315683827918 F1 score\n",
      "0.925452219989037 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.04138217998642313)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9332837565069585 precision\n",
      "0.9697538359642345 recall\n",
      "0.9511693373754873 F1 score\n",
      "0.9175954686643523 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.041669843767489834)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9453450164293538 precision\n",
      "0.9527541671266144 recall\n",
      "0.9490351311232064 F1 score\n",
      "0.9153115293257811 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.031635346435946565)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8280542986425339 precision\n",
      "0.9999448062700077 recall\n",
      "0.9059179438457885 F1 score\n",
      "0.8281107253791339 accurracy\n"
     ]
    }
   ],
   "source": [
    "compute_metrics(0.5648981081219837)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
