{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from keras.layers import Dropout\n",
    "# from keras import regularizers, optimizers\n",
    "# from keras.layers import Input, Conv1D, Dense, Flatten, Activation, UpSampling1D, MaxPooling1D, ZeroPadding1D, TimeDistributed\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.layers.core import Reshape\n",
    "#\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import RepeatVector\n",
    "# from keras.layers import TimeDistributed\n",
    "# from keras.utils import plot_model\n",
    "#\n",
    "# from keras.layers import Input, LSTM, RepeatVector\n",
    "# from keras.models import Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "5000000"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Paths\n",
    "\n",
    "ptb_char_train_path = \"datasets\\ptb\\ptb.char.train.txt\"\n",
    "ptb_char_valid_path = \"datasets\\ptb\\ptb.char.valid.txt\"\n",
    "ptb_word_train_path = \"datasets\\ptb\\ptb.train.txt\"\n",
    "ptb_word_valid_path = \"datasets\\ptb\\ptb.valid.txt\"\n",
    "ptb_word_test_path = \"datasets\\ptb\\ptb.test.txt\"\n",
    "\n",
    "wikitext2_train_path = \"datasets\\wikitext-2-v1\\wikitext-2\\wiki.train.tokens\"\n",
    "wikitext2_valid_path = \"datasets\\wikitext-2-v1\\wikitext-2\\wiki.valid.tokens\"\n",
    "wikitext2_test_path = \"datasets\\wikitext-2-v1\\wikitext-2\\wiki.test.tokens\"\n",
    "\n",
    "enwik9_path = \"datasets\\enwik9\\enwik9\"\n",
    "\n",
    "# load datasets\n",
    "ptb_char_train = datasets.Dataset(ptb_char_train_path)\n",
    "ptb_char_valid = datasets.Dataset(ptb_char_valid_path)\n",
    "ptb_word_train = datasets.Dataset(ptb_word_train_path)\n",
    "ptb_word_valid = datasets.Dataset(ptb_word_valid_path)\n",
    "ptb_word_test = datasets.Dataset(ptb_word_test_path)\n",
    "\n",
    "wikitext2_train = datasets.Dataset(wikitext2_train_path)\n",
    "wikitext2_valid = datasets.Dataset(wikitext2_valid_path)\n",
    "wikitext2_test = datasets.Dataset(wikitext2_test_path)\n",
    "\n",
    "enwik9 = datasets.Dataset(enwik9_path)\n",
    "train_offset = 9*10**7\n",
    "valid_offset = train_offset + 5*10**6\n",
    "test_offset = valid_offset + 5*10**6\n",
    "enwik9_train = enwik9.dataset[:train_offset] # first 90 million for training\n",
    "enwik9_valid = enwik9.dataset[train_offset: valid_offset] # 5 million for valid\n",
    "enwik9_test = enwik9.dataset[valid_offset: test_offset] # 5 million for test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Hyperparameters():\n",
    "    r = 5\n",
    "    k = int((90 + 40) / 2) # k < min(m,n)\n",
    "    hidden_states = 4\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, params):\n",
    "        # model parameters\n",
    "        self.r = params.r\n",
    "        self.k = params.k\n",
    "        self.lstm = tf.keras.layers.LSTM(params.hidden_states)\n",
    "\n",
    "    def mogrify(self, x_init, h_0, q, r):\n",
    "        x = x_init\n",
    "        h_prev = h_0\n",
    "        for i in range(1, self.r+1):\n",
    "            if i % 2 != 0:\n",
    "                x = 2 * tf.sigmoid(tf.matmul(q[i-1], h_prev)) * x\n",
    "                # print(\"odd %s, %s\" % (i, tf.shape(x)))\n",
    "            else:\n",
    "                h_prev = 2 * tf.sigmoid(tf.matmul(r[i-1], x)) * h_prev\n",
    "                # print(\"even %s, %s\" % (i, tf.shape(h_prev)))\n",
    "\n",
    "        return x, h_prev\n",
    "\n",
    "    def matrix_decomposition(self, m, n):\n",
    "        # currently not decomposition\n",
    "        # k < min(m,n)\n",
    "\n",
    "        q_left = tf.random.normal([m, self.k])\n",
    "        q_right = tf.random.normal([self.k, n])\n",
    "\n",
    "        r_left = tf.random.normal([n, self.k])\n",
    "        r_right = tf.random.normal([self.k, m])\n",
    "\n",
    "        return tf.matmul(q_left, q_right), tf.matmul(r_left, r_right)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "m = d\n",
    "n = 70\n",
    "a = 10\n",
    "\n",
    "x = tf.random.normal([m, a]) # d x a\n",
    "h_0 = tf.random.normal([n, a]) # n x a\n",
    "\n",
    "params = Hyperparameters()\n",
    "model = Model(params)\n",
    "\n",
    "q = [] # m x n, where m == d\n",
    "r = [] # n x m, where m == d, it's just transposed Q\n",
    "for i in range(model.r):\n",
    "    q_tmp, r_tmp = model.matrix_decomposition(m, n)\n",
    "    q.append(q_tmp)\n",
    "    r.append(r_tmp)\n",
    "\n",
    "model.mogrify(x, h_0, q, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}