{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from keras.layers import Dropout\n",
    "# from keras import regularizers, optimizers\n",
    "# from keras.layers import Input, Conv1D, Dense, Flatten, Activation, UpSampling1D, MaxPooling1D, ZeroPadding1D, TimeDistributed\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.layers.core import Reshape\n",
    "#\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import RepeatVector\n",
    "# from keras.layers import TimeDistributed\n",
    "# from keras.utils import plot_model\n",
    "#\n",
    "# from keras.layers import Input, LSTM, RepeatVector\n",
    "# from keras.models import Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "5000000"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets\n",
    "\n",
    "ptb_char_train = datasets.Dataset(\"ptb.char.train\").data\n",
    "ptb_char_valid = datasets.Dataset(\"ptb.char.valid\").data\n",
    "ptb_word_train = datasets.Dataset(\"ptb.train\").data\n",
    "ptb_word_valid = datasets.Dataset(\"ptb.valid\").data\n",
    "ptb_word_test = datasets.Dataset(\"ptb.test\").data\n",
    "\n",
    "wikitext2_train = datasets.Dataset(\"wiki.train\").data\n",
    "wikitext2_valid = datasets.Dataset(\"wiki.valid\").data\n",
    "wikitext2_test = datasets.Dataset(\"wiki.test\").data\n",
    "\n",
    "enwik9_train = datasets.Dataset(\"enwik.train\", os.path.join(\"C:\\\\\", \"Users\", \"Harry\", \".keras\", \"datasets\")).data\n",
    "enwik9_valid = datasets.Dataset(\"enwik.valid\", os.path.join(\"C:\\\\\", \"Users\", \"Harry\", \".keras\", \"datasets\")).data\n",
    "enwik9_test = datasets.Dataset(\"enwik.test\", os.path.join(\"C:\\\\\", \"Users\", \"Harry\", \".keras\", \"datasets\")).data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Hyperparameters():\n",
    "    r = 5\n",
    "    k = int((90 + 40) / 2) # k < min(m,n)\n",
    "    hidden_states = 4\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, params):\n",
    "        # model parameters\n",
    "        self.r = params.r\n",
    "        self.k = params.k\n",
    "        self.lstm = tf.keras.layers.LSTM(params.hidden_states)\n",
    "\n",
    "    def mogrify(self, x_init, h_0, q, r):\n",
    "        x = x_init\n",
    "        h_prev = h_0\n",
    "        for i in range(1, self.r+1):\n",
    "            if i % 2 != 0:\n",
    "                x = 2 * tf.sigmoid(tf.matmul(q[i-1], h_prev)) * x\n",
    "                # print(\"odd %s, %s\" % (i, tf.shape(x)))\n",
    "            else:\n",
    "                h_prev = 2 * tf.sigmoid(tf.matmul(r[i-1], x)) * h_prev\n",
    "                # print(\"even %s, %s\" % (i, tf.shape(h_prev)))\n",
    "\n",
    "        return x, h_prev\n",
    "\n",
    "    def matrix_decomposition(self, m, n):\n",
    "        # currently not decomposition\n",
    "        # k < min(m,n)\n",
    "\n",
    "        q_left = tf.random.normal([m, self.k])\n",
    "        q_right = tf.random.normal([self.k, n])\n",
    "\n",
    "        r_left = tf.random.normal([n, self.k])\n",
    "        r_right = tf.random.normal([self.k, m])\n",
    "\n",
    "        return tf.matmul(q_left, q_right), tf.matmul(r_left, r_right)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "m = d\n",
    "n = 70\n",
    "a = 10\n",
    "\n",
    "x = tf.random.normal([m, a]) # d x a\n",
    "h_0 = tf.random.normal([n, a]) # n x a\n",
    "\n",
    "params = Hyperparameters()\n",
    "model = Model(params)\n",
    "\n",
    "q = [] # m x n, where m == d\n",
    "r = [] # n x m, where m == d, it's just transposed Q\n",
    "for i in range(model.r):\n",
    "    q_tmp, r_tmp = model.matrix_decomposition(m, n)\n",
    "    q.append(q_tmp)\n",
    "    r.append(r_tmp)\n",
    "\n",
    "model.mogrify(x, h_0, q, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lstm_cell  = tf.keras.layers.LSTM(1, stateful=True)\n",
    "inputs = tf.random.normal([3, 10, 8])\n",
    "a = lstm_cell(inputs)\n",
    "print(a.shape)\n",
    "states_lstm = lstm_cell.states\n",
    "states_lstm[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, output_dim, r=5, k=65):\n",
    "        # model parameters\n",
    "        self.r = r\n",
    "        self.k = k\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = tf.keras.layers.LSTM(self.output_dim, stateful=True, return_state=True)\n",
    "\n",
    "    def forward(self, x, state = None):\n",
    "\n",
    "        x, h_prev = self.mogrify(x, )\n",
    "\n",
    "        res = self.lstm(x, initial_state=None)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def mogrify(self, x_init, h_0, q, r):\n",
    "        x = x_init\n",
    "        h_prev = h_0\n",
    "        for i in range(1, self.r+1):\n",
    "            if i % 2 != 0:\n",
    "                x = 2 * tf.sigmoid(tf.matmul(q[i-1], h_prev)) * x\n",
    "                # print(\"odd %s, %s\" % (i, tf.shape(x)))\n",
    "            else:\n",
    "                h_prev = 2 * tf.sigmoid(tf.matmul(r[i-1], x)) * h_prev\n",
    "                # print(\"even %s, %s\" % (i, tf.shape(h_prev)))\n",
    "\n",
    "        #inputs = tf.random.normal([32, 10, 8])\n",
    "        #lstm_cell(inputs, initial_state=tf.zeros([3, 3]))\n",
    "\n",
    "        return x, h_prev\n",
    "\n",
    "    def matrix_decomposition(self, m, n):\n",
    "        # currently not decomposition\n",
    "        # k < min(m,n)\n",
    "\n",
    "        q_left = tf.random.normal([m, self.k])\n",
    "        q_right = tf.random.normal([self.k, n])\n",
    "\n",
    "        r_left = tf.random.normal([n, self.k])\n",
    "        r_right = tf.random.normal([self.k, m])\n",
    "\n",
    "        return tf.matmul(q_left, q_right), tf.matmul(r_left, r_right)\n",
    "    #def __call__(self, x):\n",
    "    #    return\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs = tf.random.normal([32, 10, 8])\n",
    "outputs = tf.random.normal([32,1])\n",
    "lstm_model = Model(1)\n",
    "a = lstm_model.forward(inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def loss(target_y, predicted_y):\n",
    "    return tf.reduce_mean(tf.square(tf.subtract(target_y, predicted_y)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train(model, inputs, outputs, learning_rate):\n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(outputs, model.forward(inputs))\n",
    "    grads = t.gradient(current_loss, model.lstm.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.lstm.trainable_variables))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#train_step(inputs, [0,1,0])\n",
    "loss(lstm_model.forward(inputs)[0],lstm_model.forward(inputs)[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(lstm_model, inputs, outputs, 0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lstm_model.forward(inputs)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}