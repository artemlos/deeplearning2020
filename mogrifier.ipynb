{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from keras.layers import Dropout\n",
    "# from keras import regularizers, optimizers\n",
    "# from keras.layers import Input, Conv1D, Dense, Flatten, Activation, UpSampling1D, MaxPooling1D, ZeroPadding1D, TimeDistributed\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.layers.core import Reshape\n",
    "#\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import RepeatVector\n",
    "# from keras.layers import TimeDistributed\n",
    "# from keras.utils import plot_model\n",
    "#\n",
    "# from keras.layers import Input, LSTM, RepeatVector\n",
    "# from keras.models import Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "5000000"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Paths\n",
    "\n",
    "ptb_char_train_path = \"datasets\\ptb\\ptb.char.train.txt\"\n",
    "ptb_char_valid_path = \"datasets\\ptb\\ptb.char.valid.txt\"\n",
    "ptb_word_train_path = \"datasets\\ptb\\ptb.train.txt\"\n",
    "ptb_word_valid_path = \"datasets\\ptb\\ptb.valid.txt\"\n",
    "ptb_word_test_path = \"datasets\\ptb\\ptb.test.txt\"\n",
    "\n",
    "wikitext2_train_path = \"datasets\\wikitext-2-v1\\wikitext-2\\wiki.train.tokens\"\n",
    "wikitext2_valid_path = \"datasets\\wikitext-2-v1\\wikitext-2\\wiki.valid.tokens\"\n",
    "wikitext2_test_path = \"datasets\\wikitext-2-v1\\wikitext-2\\wiki.test.tokens\"\n",
    "\n",
    "enwik9_path = \"datasets\\enwik9\\enwik9\"\n",
    "\n",
    "# load datasets\n",
    "ptb_char_train = datasets.Dataset(ptb_char_train_path)\n",
    "ptb_char_valid = datasets.Dataset(ptb_char_valid_path)\n",
    "ptb_word_train = datasets.Dataset(ptb_word_train_path)\n",
    "ptb_word_valid = datasets.Dataset(ptb_word_valid_path)\n",
    "ptb_word_test = datasets.Dataset(ptb_word_test_path)\n",
    "\n",
    "wikitext2_train = datasets.Dataset(wikitext2_train_path)\n",
    "wikitext2_valid = datasets.Dataset(wikitext2_valid_path)\n",
    "wikitext2_test = datasets.Dataset(wikitext2_test_path)\n",
    "\n",
    "enwik9 = datasets.Dataset(enwik9_path)\n",
    "train_offset = 9*10**7\n",
    "valid_offset = train_offset + 5*10**6\n",
    "test_offset = valid_offset + 5*10**6\n",
    "enwik9_train = enwik9.dataset[:train_offset] # first 90 million for training\n",
    "enwik9_valid = enwik9.dataset[train_offset: valid_offset] # 5 million for valid\n",
    "enwik9_test = enwik9.dataset[valid_offset: test_offset] # 5 million for test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Hyperparameters():\n",
    "    r = 5\n",
    "    k = int((90 + 40) / 2) # k < min(m,n)\n",
    "    hidden_states = 4\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, params):\n",
    "        # model parameters\n",
    "        self.r = params.r\n",
    "        self.k = params.k\n",
    "        self.lstm = tf.keras.layers.LSTM(3, stateful=True)\n",
    "\n",
    "    def mogrify(self, x_init, h_0, q, r):\n",
    "        x = x_init\n",
    "        h_prev = h_0\n",
    "        for i in range(1, self.r+1):\n",
    "            if i % 2 != 0:\n",
    "                x = 2 * tf.sigmoid(tf.matmul(q[i-1], h_prev)) * x\n",
    "                # print(\"odd %s, %s\" % (i, tf.shape(x)))\n",
    "            else:\n",
    "                h_prev = 2 * tf.sigmoid(tf.matmul(r[i-1], x)) * h_prev\n",
    "                # print(\"even %s, %s\" % (i, tf.shape(h_prev)))\n",
    "                \n",
    "        #inputs = tf.random.normal([32, 10, 8])\n",
    "        #lstm_cell(inputs, initial_state=tf.zeros([3, 3]))\n",
    "        \n",
    "        return x, h_prev\n",
    "\n",
    "    def matrix_decomposition(self, m, n):\n",
    "        # currently not decomposition\n",
    "        # k < min(m,n)\n",
    "\n",
    "        q_left = tf.random.normal([m, self.k])\n",
    "        q_right = tf.random.normal([self.k, n])\n",
    "\n",
    "        r_left = tf.random.normal([n, self.k])\n",
    "        r_right = tf.random.normal([self.k, m])\n",
    "\n",
    "        return tf.matmul(q_left, q_right), tf.matmul(r_left, r_right)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "m = d\n",
    "n = 70\n",
    "a = 10\n",
    "\n",
    "x = tf.random.normal([m, a]) # d x a\n",
    "h_0 = tf.random.normal([n, a]) # n x a\n",
    "\n",
    "params = Hyperparameters()\n",
    "model = Model(params)\n",
    "\n",
    "q = [] # m x n, where m == d\n",
    "r = [] # n x m, where m == d, it's just transposed Q\n",
    "for i in range(model.r):\n",
    "    q_tmp, r_tmp = model.matrix_decomposition(m, n)\n",
    "    q.append(q_tmp)\n",
    "    r.append(r_tmp)\n",
    "\n",
    "model.mogrify(x, h_0, q, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lstm_cell  = tf.keras.layers.LSTM(1, stateful=True)\n",
    "inputs = tf.random.normal([3, 10, 8])\n",
    "a = lstm_cell(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_lstm = lstm_cell.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 100])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_lstm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, output_dim, r=5, k=65):\n",
    "        # model parameters\n",
    "        self.r = r\n",
    "        self.k = k\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = tf.keras.layers.LSTM(self.output_dim, stateful=True, return_state=True)\n",
    "\n",
    "    def forward(self, x, state = None):\n",
    "        \n",
    "        x, h_prev = self.mogrify(x, )\n",
    "        \n",
    "        res = self.lstm(x, initial_state=None)\n",
    "        \n",
    "        return res\n",
    "\n",
    "    def mogrify(self, x_init, h_0, q, r):\n",
    "        x = x_init\n",
    "        h_prev = h_0\n",
    "        for i in range(1, self.r+1):\n",
    "            if i % 2 != 0:\n",
    "                x = 2 * tf.sigmoid(tf.matmul(q[i-1], h_prev)) * x\n",
    "                # print(\"odd %s, %s\" % (i, tf.shape(x)))\n",
    "            else:\n",
    "                h_prev = 2 * tf.sigmoid(tf.matmul(r[i-1], x)) * h_prev\n",
    "                # print(\"even %s, %s\" % (i, tf.shape(h_prev)))\n",
    "                \n",
    "        #inputs = tf.random.normal([32, 10, 8])\n",
    "        #lstm_cell(inputs, initial_state=tf.zeros([3, 3]))\n",
    "        \n",
    "        return x, h_prev\n",
    "\n",
    "    def matrix_decomposition(self, m, n):\n",
    "        # currently not decomposition\n",
    "        # k < min(m,n)\n",
    "\n",
    "        q_left = tf.random.normal([m, self.k])\n",
    "        q_right = tf.random.normal([self.k, n])\n",
    "\n",
    "        r_left = tf.random.normal([n, self.k])\n",
    "        r_right = tf.random.normal([self.k, m])\n",
    "\n",
    "        return tf.matmul(q_left, q_right), tf.matmul(r_left, r_right)\n",
    "    #def __call__(self, x):\n",
    "    #    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.random.normal([32, 10, 8])\n",
    "outputs = tf.random.normal([32,1])\n",
    "lstm_model = Model(1)\n",
    "a = lstm_model.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(target_y, predicted_y):\n",
    "    return tf.reduce_mean(tf.square(tf.subtract(target_y, predicted_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train(model, inputs, outputs, learning_rate):\n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(outputs, model.forward(inputs))\n",
    "    grads = t.gradient(current_loss, model.lstm.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.lstm.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.18747838>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_step(inputs, [0,1,0])\n",
    "loss(lstm_model.forward(inputs)[0],lstm_model.forward(inputs)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(lstm_model, inputs, outputs, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
       "array([[-0.02285828],\n",
       "       [-0.15083903],\n",
       "       [-0.34129572],\n",
       "       [-0.15409048],\n",
       "       [ 0.2064351 ],\n",
       "       [ 0.09367777],\n",
       "       [-0.15006217],\n",
       "       [-0.1653357 ],\n",
       "       [-0.12802078],\n",
       "       [-0.004516  ],\n",
       "       [-0.02686472],\n",
       "       [ 0.00336589],\n",
       "       [-0.12070271],\n",
       "       [-0.15902609],\n",
       "       [-0.24169014],\n",
       "       [ 0.02023081],\n",
       "       [-0.22884719],\n",
       "       [-0.19811633],\n",
       "       [-0.06428994],\n",
       "       [ 0.06493499],\n",
       "       [ 0.2514327 ],\n",
       "       [-0.10866537],\n",
       "       [ 0.00651824],\n",
       "       [ 0.41850758],\n",
       "       [-0.10629941],\n",
       "       [ 0.13327403],\n",
       "       [ 0.18763158],\n",
       "       [ 0.11388085],\n",
       "       [ 0.10960069],\n",
       "       [ 0.01668897],\n",
       "       [ 0.3864037 ],\n",
       "       [-0.00433558]], dtype=float32)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.forward(inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 10, 8), dtype=float32, numpy=\n",
       "array([[[ 0.64471984,  0.32261553, -0.9018336 , ..., -1.2121781 ,\n",
       "          1.7112691 , -0.06128946],\n",
       "        [-0.47612506,  2.8363483 ,  0.6488025 , ...,  0.5639938 ,\n",
       "         -0.89272785,  1.2869956 ],\n",
       "        [-1.826292  , -1.5898417 ,  1.720043  , ...,  0.35576206,\n",
       "          1.6709523 , -1.20416   ],\n",
       "        ...,\n",
       "        [ 1.3392175 , -0.30057114, -0.312073  , ...,  2.5556269 ,\n",
       "          0.43465012,  1.5250355 ],\n",
       "        [-0.94405586,  1.4114699 , -0.27489978, ..., -0.6357156 ,\n",
       "          0.08776896, -0.78510475],\n",
       "        [ 1.333204  , -0.90804017,  1.241809  , ...,  0.68062395,\n",
       "         -0.2806706 , -1.7576079 ]],\n",
       "\n",
       "       [[ 0.8873787 , -0.446249  , -0.36244833, ...,  1.2092675 ,\n",
       "          0.06869007,  1.0626215 ],\n",
       "        [-1.1851996 ,  0.79778206,  0.57506305, ...,  0.27277756,\n",
       "          0.19615012, -1.2605242 ],\n",
       "        [-0.15114455,  0.35635394, -0.91550314, ..., -1.1986965 ,\n",
       "         -0.28736755, -1.4271721 ],\n",
       "        ...,\n",
       "        [-0.00333271, -1.5405953 , -0.66335124, ...,  1.3992025 ,\n",
       "         -1.3207566 ,  1.1162362 ],\n",
       "        [ 0.20644923, -1.759286  ,  2.0209627 , ..., -0.03334965,\n",
       "          0.83648366,  1.3027323 ],\n",
       "        [-0.06669339, -0.46986276, -0.32855573, ...,  1.3540735 ,\n",
       "         -0.10463763, -1.1016587 ]],\n",
       "\n",
       "       [[ 0.07106076,  1.1757344 ,  0.07997908, ...,  0.62197214,\n",
       "         -0.85189724,  0.6625829 ],\n",
       "        [ 0.41312146, -0.17421013, -1.0750003 , ...,  0.35032257,\n",
       "          0.59043413,  0.11702217],\n",
       "        [-0.13235559, -0.01649379, -0.68741524, ..., -1.3515596 ,\n",
       "         -0.52056575, -0.17365462],\n",
       "        ...,\n",
       "        [-0.08711662, -1.3399122 ,  2.475864  , ..., -0.21745878,\n",
       "          1.3497994 ,  1.8781931 ],\n",
       "        [ 0.62424517, -0.8264038 ,  0.7760226 , ...,  0.94778496,\n",
       "         -0.26768312,  0.91260856],\n",
       "        [ 0.6769485 ,  0.2626639 , -0.6474228 , ..., -0.5463788 ,\n",
       "         -0.577409  ,  0.9720433 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.9958579 ,  1.8348176 , -2.3005023 , ..., -0.42030925,\n",
       "         -2.2423115 ,  1.3440742 ],\n",
       "        [ 1.2659378 , -0.10748502,  0.67076063, ..., -0.5701563 ,\n",
       "         -0.6274186 ,  0.8548747 ],\n",
       "        [ 0.25756368, -0.69419324,  0.4202453 , ..., -1.3779523 ,\n",
       "          0.6540034 , -0.9475041 ],\n",
       "        ...,\n",
       "        [ 0.7612244 , -0.5273797 ,  0.34184062, ...,  0.91537946,\n",
       "          0.5802894 ,  2.43233   ],\n",
       "        [-0.6485632 ,  1.1090271 , -0.3655561 , ...,  0.14579016,\n",
       "         -0.7456747 , -0.05918464],\n",
       "        [ 1.3945022 ,  0.2683694 ,  0.36434552, ...,  0.07130685,\n",
       "         -0.68509436, -0.9653158 ]],\n",
       "\n",
       "       [[-0.3742138 , -1.4129523 ,  1.5083454 , ...,  0.78226095,\n",
       "          1.4477355 , -1.1749396 ],\n",
       "        [ 0.16745377,  1.5613292 , -0.29850435, ..., -1.3092781 ,\n",
       "         -1.0618794 ,  0.75081015],\n",
       "        [ 0.16706808, -0.9602115 ,  0.34861803, ..., -0.43302038,\n",
       "         -0.35667342,  0.3769541 ],\n",
       "        ...,\n",
       "        [ 0.3558854 , -1.1563642 , -0.48084152, ...,  0.38415343,\n",
       "         -1.4002466 ,  0.83056074],\n",
       "        [-0.8094086 , -0.16571794, -0.00600714, ..., -1.2667937 ,\n",
       "          1.0533607 ,  1.121471  ],\n",
       "        [-0.28557608,  0.7956409 , -0.6745298 , ..., -0.6582413 ,\n",
       "         -0.04638718,  0.70796263]],\n",
       "\n",
       "       [[-0.8644256 , -0.26818213,  1.072467  , ..., -0.22608618,\n",
       "          1.3125417 , -0.3598984 ],\n",
       "        [-0.48078665, -0.4054361 ,  0.8067204 , ..., -1.4508798 ,\n",
       "          0.93836284,  0.1546375 ],\n",
       "        [-1.0820909 ,  0.06896374, -0.19756955, ..., -0.63260144,\n",
       "          2.9384205 ,  0.02575153],\n",
       "        ...,\n",
       "        [ 0.221494  ,  0.9405642 ,  1.3493218 , ...,  2.1960506 ,\n",
       "          0.20401464,  0.43809858],\n",
       "        [ 0.15159535, -0.9534424 , -0.67516345, ..., -1.1787025 ,\n",
       "          0.27521694, -0.504408  ],\n",
       "        [ 0.54322356, -0.2617393 , -1.0183463 , ...,  0.29044583,\n",
       "         -0.01398476, -1.0999728 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
